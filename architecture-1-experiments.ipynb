{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This cell comes from starting a new Kaggle notebook\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# This prints all of the file names in the input directory\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-08T23:09:34.898961Z","iopub.execute_input":"2023-12-08T23:09:34.899316Z","iopub.status.idle":"2023-12-08T23:09:35.262727Z","shell.execute_reply.started":"2023-12-08T23:09:34.899281Z","shell.execute_reply":"2023-12-08T23:09:35.261689Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# This is needed if attempting to use TPU in Kaggle's environment\n#!pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:35.264347Z","iopub.execute_input":"2023-12-08T23:09:35.264767Z","iopub.status.idle":"2023-12-08T23:09:35.268395Z","shell.execute_reply.started":"2023-12-08T23:09:35.264736Z","shell.execute_reply":"2023-12-08T23:09:35.267501Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# CITATION: this cell is a part of the following notebook, that I slightly changed:\n#\n# Thite, S. (2023, October 9). UBC ovarian cancer subtype classification-CNN. Kaggle. \n# https://www.kaggle.com/code/sunilthite/ubc-ovarian-cancer-subtype-classification-cnn/notebook\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.metrics import classification_report , confusion_matrix , accuracy_score , auc\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\n#from google.colab.patches import cv2_imshow\nfrom PIL import Image \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Input, Dense,Conv2D , MaxPooling2D, Flatten,BatchNormalization,Dropout\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport tensorflow_hub as hub ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:35.269641Z","iopub.execute_input":"2023-12-08T23:09:35.269957Z","iopub.status.idle":"2023-12-08T23:09:48.939973Z","shell.execute_reply.started":"2023-12-08T23:09:35.269931Z","shell.execute_reply":"2023-12-08T23:09:48.938971Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# If wanting to use a TPU\n# CITATION: this code is from:\n# Holbrook, R. (2020, September 24). Getting started with tpus. Kaggle. \n# https://www.kaggle.com/code/ryanholbrook/getting-started-with-tpus \n\"\"\"\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:48.943043Z","iopub.execute_input":"2023-12-08T23:09:48.944244Z","iopub.status.idle":"2023-12-08T23:09:48.951358Z","shell.execute_reply.started":"2023-12-08T23:09:48.944199Z","shell.execute_reply":"2023-12-08T23:09:48.950185Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"\"\\ntry:\\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \\n    print('Running on TPU ', tpu.master())\\nexcept ValueError:\\n    tpu = None\\n\""},"metadata":{}}]},{"cell_type":"code","source":"# If wanting to use a TPU\n# CITATION: this code is from:\n# Holbrook, R. (2020, September 24). Getting started with tpus. Kaggle. \n# https://www.kaggle.com/code/ryanholbrook/getting-started-with-tpus \n\"\"\"\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:48.953010Z","iopub.execute_input":"2023-12-08T23:09:48.953384Z","iopub.status.idle":"2023-12-08T23:09:49.055547Z","shell.execute_reply.started":"2023-12-08T23:09:48.953349Z","shell.execute_reply":"2023-12-08T23:09:49.054578Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nif tpu:\\n    tf.config.experimental_connect_to_cluster(tpu)\\n    tf.tpu.experimental.initialize_tpu_system(tpu)\\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\\nelse:\\n    strategy = tf.distribute.get_strategy() \\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"**Data loading and preprocessing**\n\nCITATION: this section of the notebook is a part of the following notebook, that I slightly changed:\n\nThite, S. (2023, October 9). UBC ovarian cancer subtype classification-CNN. Kaggle. \nhttps://www.kaggle.com/code/sunilthite/ubc-ovarian-cancer-subtype-classification-cnn/notebook\n","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/UBC-OCEAN/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.056951Z","iopub.execute_input":"2023-12-08T23:09:49.057256Z","iopub.status.idle":"2023-12-08T23:09:49.082728Z","shell.execute_reply.started":"2023-12-08T23:09:49.057218Z","shell.execute_reply":"2023-12-08T23:09:49.081801Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# The paths for the medical images\npath_train = \"/kaggle/input/UBC-OCEAN/train_images\"\npath_test = \"/kaggle/input/UBC-OCEAN/test_images\"\ntrain_folder = os.listdir(path_train)\ntest_folder = os.listdir(path_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.083961Z","iopub.execute_input":"2023-12-08T23:09:49.084244Z","iopub.status.idle":"2023-12-08T23:09:49.229127Z","shell.execute_reply.started":"2023-12-08T23:09:49.084219Z","shell.execute_reply":"2023-12-08T23:09:49.228327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# The paths for the thumbnail images\npath_train_copy = \"/kaggle/input/UBC-OCEAN/train_thumbnails\"\npath_test_copy = \"/kaggle/input/UBC-OCEAN/test_thumbnails\"\ntrain_folder_copy = os.listdir(path_train_copy)\ntest_folder_copy = os.listdir(path_test_copy)\n\nprint(len(train_folder_copy))\nprint(len(test_folder_copy))","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.230171Z","iopub.execute_input":"2023-12-08T23:09:49.230453Z","iopub.status.idle":"2023-12-08T23:09:49.337453Z","shell.execute_reply.started":"2023-12-08T23:09:49.230428Z","shell.execute_reply":"2023-12-08T23:09:49.336515Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"513\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df_tma = train_df[train_df['is_tma']==True]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.338786Z","iopub.execute_input":"2023-12-08T23:09:49.339394Z","iopub.status.idle":"2023-12-08T23:09:49.352687Z","shell.execute_reply.started":"2023-12-08T23:09:49.339359Z","shell.execute_reply":"2023-12-08T23:09:49.351555Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df_no_tma = train_df[train_df['is_tma']==False]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.353864Z","iopub.execute_input":"2023-12-08T23:09:49.354148Z","iopub.status.idle":"2023-12-08T23:09:49.366812Z","shell.execute_reply.started":"2023-12-08T23:09:49.354123Z","shell.execute_reply":"2023-12-08T23:09:49.365719Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df_no_tma['image_id_path'] = [f\"{i}_thumbnail.png\" for i in train_df_no_tma['image_id']]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.368032Z","iopub.execute_input":"2023-12-08T23:09:49.368334Z","iopub.status.idle":"2023-12-08T23:09:49.380769Z","shell.execute_reply.started":"2023-12-08T23:09:49.368309Z","shell.execute_reply":"2023-12-08T23:09:49.379863Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df_tma['image_id_path'] = [f\"{i}.png\" for i in train_df_tma['image_id']]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.385397Z","iopub.execute_input":"2023-12-08T23:09:49.385776Z","iopub.status.idle":"2023-12-08T23:09:49.393733Z","shell.execute_reply.started":"2023-12-08T23:09:49.385749Z","shell.execute_reply":"2023-12-08T23:09:49.392864Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_thumbnails_folder = train_folder_copy","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.394875Z","iopub.execute_input":"2023-12-08T23:09:49.395307Z","iopub.status.idle":"2023-12-08T23:09:49.405286Z","shell.execute_reply.started":"2023-12-08T23:09:49.395275Z","shell.execute_reply":"2023-12-08T23:09:49.404355Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"image_data = []\nimage_label = []\npath = \"/kaggle/input/UBC-OCEAN/train_thumbnails\"\npath1=\"/kaggle/input/UBC-OCEAN/train_images/\"\nfor img , label in zip(train_df_no_tma['image_id_path'],train_df_no_tma['label']):\n    image = Image.open(\"/kaggle/input/UBC-OCEAN/train_thumbnails/\"+img)\n    image = image.resize((256,256))\n    image = image.convert(\"RGB\")\n    image = np.array(image)\n    image_data.append(image)\n    image_label.append(label)\n\nfor img , label in zip(train_df_tma['image_id_path'],train_df_tma['label']):\n    image = Image.open(\"/kaggle/input/UBC-OCEAN/train_images/\"+img)\n    image = image.resize((256,256))\n    image = image.convert(\"RGB\")\n    image = np.array(image)\n    image_data.append(image)\n    image_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:09:49.406584Z","iopub.execute_input":"2023-12-08T23:09:49.406916Z","iopub.status.idle":"2023-12-08T23:12:21.584631Z","shell.execute_reply.started":"2023-12-08T23:09:49.406890Z","shell.execute_reply":"2023-12-08T23:12:21.583587Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"set(image_label)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.585930Z","iopub.execute_input":"2023-12-08T23:12:21.586248Z","iopub.status.idle":"2023-12-08T23:12:21.592376Z","shell.execute_reply.started":"2023-12-08T23:12:21.586221Z","shell.execute_reply":"2023-12-08T23:12:21.591500Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'CC', 'EC', 'HGSC', 'LGSC', 'MC'}"},"metadata":{}}]},{"cell_type":"code","source":"image_label_1 = []\nfor i in image_label:\n    if i==\"CC\":\n        image_label_1.append(0)\n    elif i==\"EC\":\n        image_label_1.append(1)\n    elif i==\"HGSC\":\n        image_label_1.append(2)\n    elif i==\"LGSC\":\n        image_label_1.append(3)\n    elif i==\"MC\":\n        image_label_1.append(4)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.593691Z","iopub.execute_input":"2023-12-08T23:12:21.593989Z","iopub.status.idle":"2023-12-08T23:12:21.604200Z","shell.execute_reply.started":"2023-12-08T23:12:21.593944Z","shell.execute_reply":"2023-12-08T23:12:21.603363Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x = np.array(image_data)\ny = np.array(image_label_1)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.605229Z","iopub.execute_input":"2023-12-08T23:12:21.605538Z","iopub.status.idle":"2023-12-08T23:12:21.648661Z","shell.execute_reply.started":"2023-12-08T23:12:21.605484Z","shell.execute_reply":"2023-12-08T23:12:21.647584Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.15,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.649957Z","iopub.execute_input":"2023-12-08T23:12:21.650280Z","iopub.status.idle":"2023-12-08T23:12:21.688082Z","shell.execute_reply.started":"2023-12-08T23:12:21.650253Z","shell.execute_reply":"2023-12-08T23:12:21.687212Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x_train_scaled = x_train/255\nx_test_scaled = x_test/255","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.689314Z","iopub.execute_input":"2023-12-08T23:12:21.689644Z","iopub.status.idle":"2023-12-08T23:12:21.965200Z","shell.execute_reply.started":"2023-12-08T23:12:21.689617Z","shell.execute_reply":"2023-12-08T23:12:21.964349Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.15,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:21.966324Z","iopub.execute_input":"2023-12-08T23:12:21.966653Z","iopub.status.idle":"2023-12-08T23:12:22.003857Z","shell.execute_reply.started":"2023-12-08T23:12:21.966626Z","shell.execute_reply":"2023-12-08T23:12:22.003042Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# This is my addition\n# In some runs, I would delete some of the arrays that are no longer needed\n# This is to save space in the Kaggle environment as it is limited\nimport gc\ndel x\ndel y\ndel image_data\ndel image_label_1\ndel image_label\ndel train_df\ndel train_df_tma\ndel train_df_no_tma\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:22.004977Z","iopub.execute_input":"2023-12-08T23:12:22.005296Z","iopub.status.idle":"2023-12-08T23:12:22.225258Z","shell.execute_reply.started":"2023-12-08T23:12:22.005269Z","shell.execute_reply":"2023-12-08T23:12:22.224271Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"markdown","source":"**Experiments**\n\nThis section is mostly my code","metadata":{}},{"cell_type":"code","source":"# This is the function I wrote the creates a model of the first architecture with the given hyperparameter values\n# The first architecture is a CNN with a convolutional layer followed my a max pooling layer, potentially repeated multiple times\n# The CNN is then connected to an MLP\ndef getModel(model, num_layers, kernel_s, max_pool, stride, learning_rate):\n    if num_layers == 1:\n        model.add(Conv2D(filters=64,kernel_size=(kernel_s,kernel_s),strides=(stride,stride),activation='relu',input_shape=(256,256,3)))\n        model.add(MaxPooling2D(pool_size=(max_pool,max_pool)))\n    else:\n        model.add(Conv2D(filters=200,kernel_size=(kernel_s,kernel_s),strides=(stride,stride),activation='relu',input_shape=(256,256,3)))\n        model.add(MaxPooling2D(pool_size=(max_pool,max_pool)))\n      \n        for i in range(num_layers - 1):\n            model.add(Conv2D(filters=200 - int(136/(num_layers - 1 - i)),kernel_size=(kernel_s,kernel_s),strides=(stride,stride),activation='relu'))\n            model.add(MaxPooling2D(pool_size=(max_pool,max_pool)))\n                             \n    model.add(Flatten())\n    model.add(Dense(units=512,activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=256,activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=5,activation='softmax'))\n\n    opti = keras.optimizers.Adam(learning_rate = learning_rate)\n    \n    model.compile(optimizer=opti,loss=\"sparse_categorical_crossentropy\",\n                 metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-08T23:12:22.226463Z","iopub.execute_input":"2023-12-08T23:12:22.226811Z","iopub.status.idle":"2023-12-08T23:12:22.246025Z","shell.execute_reply.started":"2023-12-08T23:12:22.226785Z","shell.execute_reply":"2023-12-08T23:12:22.245096Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# This is my code for the grid search over the different hyperparameter values\n# The part of the code in this cell that is not mine is the 5-fold cross validation\n# CITATION: that part of the code is from:\n#\n# Versloot, C. (2020, June 11). how-to-use-k-fold-cross-validation-with-keras.md. GitHub. \n# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md \n\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport pandas as pd\n  \n# These are the hyperparameter values I experimented with\n# There are 288 combinations here\nnumLayers = [1, 2, 3, 4, 5, 6]\nnumEpochs = [1, 5, 10, 20]\nkernel_sizes = [2, 3, 4]\nmax_pool= 2\nstride = 1\nlearning_rates = [0.001, 0.01, 0.05, 0.1]\n\naccuracies= []\nlosses = []\n\n# The actual grid search over the hyperparameter values above\nfor num_layers in numLayers:\n    for epoch in numEpochs:\n        for kernel_size in kernel_sizes:\n            for learning_rate in learning_rates:\n                # This is the code from the citation above\n                acc_per_fold = []\n                loss_per_fold = []\n\n                x_values = np.concatenate((x_train_scaled, x_test_scaled), axis=0)\n                y_values = np.concatenate((y_train, y_test), axis=0)\n\n                # Define the K-fold Cross Validator\n                kfold = KFold(n_splits=5, shuffle=True)\n                # K-fold Cross Validation model evaluation\n                fold_no = 1\n                for train, test in kfold.split(x_values, y_values):\n                    # This is to utilize the TPU\n                    # The next two lines after this one need to be indented to use this\n                    # This is from the citation for the TPU usage at the beginning of this notebook\n                    # with strategy.scope():\n                    model = Sequential()\n                    getModel(model, num_layers, kernel_size, max_pool, stride, learning_rate)\n\n                    # Generate a print\n                    print('------------------------------------------------------------------------')\n                    print(f'Training for fold {fold_no} ...')\n\n                    # Fit data to model\n                    history = model.fit(x_values[train], y_values[train],\n                              batch_size=16,\n                              epochs=epoch)\n\n                    # Generate generalization metrics\n                    scores = model.evaluate(x_values[test], y_values[test], verbose=0)\n                    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n                    acc_per_fold.append(scores[1] * 100)\n                    loss_per_fold.append(scores[0])\n\n                    # Increase fold number\n                    fold_no = fold_no + 1\n                    \n                    # From here it is back to my own code\n                    del model\n                    del history\n                    gc.collect()\n\n                average_accuracy = np.mean(acc_per_fold)\n                average_loss = np.mean(loss_per_fold)\n                accuracies.append([num_layers, epoch, kernel_size, learning_rate, average_accuracy])\n                losses.append([num_layers, epoch, kernel_size, learning_rate, average_loss])\n\n# This is to save the results to a file\n# I layer organized this file in Google Sheets so it is more clear\ndf = pd.DataFrame(accuracies)\ndf.to_csv('/kaggle/working/architecture1ValAccuracies', index=False)\n\ndf = pd.DataFrame(losses)\ndf.to_csv('/kaggle/working/architecture1ValLosses', index=False)\n\n# I did not include the output for this cell as it is extremely long","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}